= Kafka schema metadata SMT

This project extracts from the kafka AVRO message kafka schema related information and exposes as headers.

A https://docs.confluent.io/platform/current/connect/concepts.html[Kafka Schema metadata Single Message Transformation (SMT)] that reads the serialized https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html[wire format header] of Confluent's `KafkaAvroSerializer`, performs a lookup against a source https://github.com/confluentinc/schema-registry[Confluent Schema Registry] for the ID in the message, and queries all the schema metadata of the AVRO message and adds them as headers.

== Schema Metadata Headers

This SMT extracts from the message the metadata of the schema and adds them as headers. Following are the headers:

.Schema Metadata Headers
[%header,cols="1,1a"]
|===
|Header Name
|Description
a|MSG_KEY
a|Every kafka message needs to have a Key. This header extracts the key from the message and exposes as a header.

a|MSG_TOPIC
a|The Kafka topic in which this message is stored.

a|MSG_TIMESTAMP
a|Timestamp of the Kafka message. Please note that when you add this SMT to the source connector, the record timestamp will not be set.

a|MSG_KEY_SCHEMA_ID
a|The schema id of the AVRO message key. Note that this is an internal id generated by the kafka schema registry.

a|MSG_KEY_SCHEMA_VERSION
a|The schema version of the AVRO message key. A new version will created upon change in the AVRO message structure such add/update/delete of a field.

a|MSG_KEY_SUBJECT
a|The subject name of the message key.

a|MSG_VALUE_SCHEMA_ID
a|The schema id of the AVRO message value. Note that this is an internal id generated by the Kafka schema registry.

a|MSG_VALUE_SCHEMA_VERSION
a|The schema version of the AVRO message value. A new version will created upon change in the AVRO message structure such add/update/delete of a field.

a|MSG_VALUE_SUBJECT
a|The subject name of the message value.
|===

== Installation

. Edit the Kafka Connect worker properties file on each worker to include a new directory. For example, `/opt/kafka-connect/plugins`
[source, bash]
----
plugin.path=/usr/share/java,/opt/kafka-connect/plugins
----

[start=2]
. Build this project
[source, bash]
----
./gradlew clean jar
----

[start=3]
. Copy the JAR from `build/libs` to all Kafka Connect workers under a directory set by `plugin.path`

. (Re)start Kafka Connect processes

== References

* Confluent Kafka Schema Registry: https://github.com/confluentinc/schema-registry
* Kafka connect concepts: https://docs.confluent.io/platform/current/connect/concepts.html
* Formats, Serializers, and Deserializers: https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html
